{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">92,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m51\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m92,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,723</span> (620.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m158,723\u001b[0m (620.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,465</span> (619.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m158,465\u001b[0m (619.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"models/Sprint_Start.h5\", custom_objects={\"mse\": tf.keras.losses.MeanSquaredError()})\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "def extract_features_from_video(frames):\n",
    "    # Load a pre-trained CNN\n",
    "    feature_extractor = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    feature_extractor.trainable = False\n",
    "\n",
    "    # Preprocess frames\n",
    "    frames = preprocess_input(frames)  # Normalize frames for MobileNetV2\n",
    "    features = feature_extractor.predict(frames)  # Extract features\n",
    "\n",
    "    # Global Average Pooling to reduce dimensionality\n",
    "    pooled_features = tf.reduce_mean(features, axis=(1, 2))  # Shape: (num_frames, feature_dim)\n",
    "\n",
    "    # Reduce to 51 dimensions using PCA\n",
    "    pca = PCA(n_components=51)\n",
    "    reduced_features = pca.fit_transform(pooled_features.numpy())  # Ensure numpy array\n",
    "    return reduced_featuresfeatures.numpy()  # Convert to NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# def aggregate_features(features):\n",
    "#     # Apply PCA to reduce dimensionality to 51 features\n",
    "#     pca = PCA(n_components=51)\n",
    "#     aggregated_features = pca.fit_transform(features)  # Shape: (num_frames, 51)\n",
    "#     return aggregated_features\n",
    "\n",
    "def aggregate_features(features):\n",
    "    n_samples, n_features = features.shape\n",
    "    if n_samples < 51 or n_features < 51:\n",
    "        # Directly use mean as a fallback for small videos\n",
    "        mean_features = np.mean(features, axis=0).reshape(1, -1)\n",
    "        padded_features = np.zeros((1, 51))\n",
    "        padded_features[0, :mean_features.shape[1]] = mean_features\n",
    "        return np.repeat(padded_features, n_samples, axis=0)  # Repeat to match samples\n",
    "    else:\n",
    "        # Perform PCA with 51 components\n",
    "        pca = PCA(n_components=51)\n",
    "        return pca.fit_transform(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPORT_BRANCH_MODEL_MAPPING = {\n",
    "    \"Sprint Start\": \"models/Sprint_Start.h5\",\n",
    "    \"Sprint Running\": \"models/Sprint.h5\",\n",
    "    \"Shot Put\": \"models/Kogelstonen.h5\",\n",
    "    \"Relay Receiver\": \"models/Estafette.h5\",\n",
    "    \"Long Jump\": \"models/Verspringen.h5\",\n",
    "    \"Javelin\": \"models/Speerwerpen.h5\",\n",
    "    \"High Jump\": \"models/Hoogspringen.h5\",\n",
    "    \"Discus Throw\": \"models/Discurwepen.h5\",\n",
    "    \"Hurdling\": \"models/Hordelopen.h5\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, sport_branch):\n",
    "    model_path = SPORT_BRANCH_MODEL_MAPPING.get(sport_branch)\n",
    "    if not model_path:\n",
    "        return f\"Error: No model found for sport branch: {sport_branch}\"\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path, custom_objects={\"mse\": tf.keras.losses.MeanSquaredError()})\n",
    "    except Exception as e:\n",
    "        return f\"Error loading model: {str(e)}\"\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return \"Error: Couldn't read video stream from file\"\n",
    "\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        frame = frame / 255.0\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    frames = np.array(frames)\n",
    "    if frames.size == 0:\n",
    "        return \"Error: No frames extracted from video.\"\n",
    "\n",
    "    features = extract_features_from_video(frames)\n",
    "\n",
    "    try:\n",
    "        aggregated_features = aggregate_features(features)\n",
    "        print(f\"Aggregated features for {video_path}: {aggregated_features[:5]}\")  # Log features\n",
    "    except Exception as e:\n",
    "        return f\"Error during feature aggregation: {str(e)}\"\n",
    "\n",
    "    predictions = model.predict(aggregated_features)\n",
    "    print(f\"Predictions for {video_path}: {predictions[:5]}\")  # Log predictions\n",
    "\n",
    "    final_grade = np.mean(predictions)\n",
    "    final_grade = np.clip(final_grade, 0, 5)\n",
    "\n",
    "    return f\"Final Grade: {final_grade:.2f} / 5\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_video(frames):\n",
    "    # Load a pre-trained CNN\n",
    "    feature_extractor = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    feature_extractor.trainable = False\n",
    "\n",
    "    # Preprocess frames\n",
    "    frames = preprocess_input(frames)  # Normalize frames for MobileNetV2\n",
    "    features = feature_extractor.predict(frames)  # Extract features\n",
    "\n",
    "    # Global Average Pooling to reduce dimensionality\n",
    "    pooled_features = tf.reduce_mean(features, axis=(1, 2))  # Shape: (num_frames, feature_dim)\n",
    "\n",
    "    # Reduce to 51 dimensions using PCA\n",
    "    pca = PCA(n_components=51)\n",
    "    reduced_features = pca.fit_transform(pooled_features.numpy())  # Ensure numpy array\n",
    "    return reduced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(61548) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 240ms/step\n",
      "Aggregated features for /private/var/folders/wy/99dkswn162g8dvl4934_v1rr0000gn/T/gradio/6d018de720eea58f30db5c238742a615b46e8f9fdca9bf5b7895088954027c6a/10000000 6110465729036786 6689576925545987563 n.mp4: [[ 8.53632838e-02 -1.23045444e+00 -2.88924396e-01  8.26340020e-01\n",
      "  -2.08476231e-01  2.04020739e-01  1.52514884e-02  2.37199385e-02\n",
      "  -3.62466526e-04  1.19489490e-03  3.67494076e-02 -3.55127901e-02\n",
      "  -5.14904149e-02  2.10678801e-02 -5.03515126e-03 -6.72045397e-03\n",
      "  -6.15637610e-03 -6.31009927e-03 -1.82876771e-03 -2.41852482e-03\n",
      "   2.11959332e-03 -2.56938906e-03 -2.64676474e-03  6.12409378e-04\n",
      "  -4.64173360e-03  2.77493009e-03 -1.54450070e-03  5.23407361e-04\n",
      "   2.55867373e-03 -4.86786943e-04 -3.44943575e-04  3.18887207e-04\n",
      "  -1.58915389e-03  5.00214286e-04 -5.66194183e-04 -1.51130790e-03\n",
      "  -7.85136945e-04  5.73512698e-05 -7.46871083e-05 -6.30332332e-04\n",
      "  -2.75992032e-04 -9.44480242e-04  2.88610405e-04 -1.73483801e-04\n",
      "   8.14009854e-06  4.05672472e-04 -6.68663473e-04 -3.31079034e-04\n",
      "  -7.71325431e-04  3.05761969e-05 -8.85223679e-04]\n",
      " [ 8.55366737e-02 -1.23034656e+00 -2.88837999e-01  8.26286137e-01\n",
      "  -2.08594725e-01  2.03869998e-01  1.51002342e-02  2.36698259e-02\n",
      "  -3.68478271e-04  1.15972396e-03  3.66456360e-02 -3.55252884e-02\n",
      "  -5.15215434e-02  2.08518934e-02 -5.18192071e-03 -6.71891589e-03\n",
      "  -6.01119921e-03 -6.35039946e-03 -1.53707527e-03 -2.55027227e-03\n",
      "   2.35536066e-03 -2.74603465e-03 -2.69504590e-03  5.78922860e-04\n",
      "  -4.39388119e-03  2.76263966e-03 -1.52187282e-03  5.41645742e-04\n",
      "   2.49338383e-03 -4.44212812e-04 -2.30989492e-04  2.67140771e-04\n",
      "  -1.61355000e-03  6.06268295e-04 -5.22344140e-04 -1.51938910e-03\n",
      "  -8.92342243e-04  8.32076548e-05 -7.48144448e-05 -5.62103058e-04\n",
      "  -2.37014188e-04 -8.56584928e-04  2.06846176e-04 -9.27479850e-05\n",
      "   5.86854840e-05  4.41858603e-04 -6.03607157e-04 -3.68607900e-04\n",
      "  -7.12113921e-04  5.39665562e-05 -7.71480903e-04]\n",
      " [ 8.56788903e-02 -1.23025775e+00 -2.88765758e-01  8.26232791e-01\n",
      "  -2.08693117e-01  2.03706786e-01  1.49954250e-02  2.36887448e-02\n",
      "  -3.70151800e-04  1.11795869e-03  3.65568772e-02 -3.55533734e-02\n",
      "  -5.15328981e-02  2.06855666e-02 -5.35488175e-03 -6.73901523e-03\n",
      "  -5.91922831e-03 -6.37518428e-03 -1.26799673e-03 -2.68076174e-03\n",
      "   2.58234004e-03 -2.90398928e-03 -2.79023498e-03  5.26034681e-04\n",
      "  -4.20083571e-03  2.76351930e-03 -1.54356263e-03  5.69465919e-04\n",
      "   2.43533915e-03 -3.78574303e-04 -1.34453672e-04  2.18591580e-04\n",
      "  -1.62667804e-03  6.80475729e-04 -4.75789246e-04 -1.49376248e-03\n",
      "  -9.63845057e-04  1.22641213e-04 -8.25761672e-05 -4.81397234e-04\n",
      "  -2.34039879e-04 -7.78684043e-04  1.40867167e-04 -3.21922053e-05\n",
      "   1.04001869e-04  4.62122553e-04 -5.32085774e-04 -4.22929210e-04\n",
      "  -6.60206599e-04  7.98381443e-05 -6.61167840e-04]\n",
      " [ 8.56666267e-02 -1.23025560e+00 -2.88746804e-01  8.26242983e-01\n",
      "  -2.08696350e-01  2.03687891e-01  1.50082726e-02  2.37095468e-02\n",
      "  -3.86140018e-04  1.11279497e-03  3.65734473e-02 -3.55564468e-02\n",
      "  -5.15328422e-02  2.06737053e-02 -5.35225263e-03 -6.74276147e-03\n",
      "  -5.92216570e-03 -6.36870973e-03 -1.27734360e-03 -2.68334290e-03\n",
      "   2.57332716e-03 -2.90661422e-03 -2.78727827e-03  5.20492147e-04\n",
      "  -4.20117192e-03  2.77133728e-03 -1.54170045e-03  5.72548364e-04\n",
      "   2.44166935e-03 -3.76500509e-04 -1.33363574e-04  2.22095623e-04\n",
      "  -1.63344108e-03  6.79762452e-04 -4.73540567e-04 -1.49250333e-03\n",
      "  -9.62259306e-04  1.28314263e-04 -8.47741467e-05 -4.81657567e-04\n",
      "  -2.31268452e-04 -7.81940529e-04  1.43616431e-04 -3.63426334e-05\n",
      "   1.07163331e-04  4.58345894e-04 -5.36376785e-04 -4.23003221e-04\n",
      "  -6.67560671e-04  7.76169982e-05 -6.58404315e-04]\n",
      " [ 8.56660977e-02 -1.23025572e+00 -2.88741857e-01  8.26243460e-01\n",
      "  -2.08696321e-01  2.03687385e-01  1.50090596e-02  2.37116609e-02\n",
      "  -3.86896048e-04  1.11082371e-03  3.65728401e-02 -3.55559252e-02\n",
      "  -5.15320934e-02  2.06732806e-02 -5.34881698e-03 -6.74131885e-03\n",
      "  -5.92702534e-03 -6.36884989e-03 -1.27617503e-03 -2.68212380e-03\n",
      "   2.57334788e-03 -2.90494808e-03 -2.78513483e-03  5.17973036e-04\n",
      "  -4.20327252e-03  2.77474686e-03 -1.54393178e-03  5.71562967e-04\n",
      "   2.44508684e-03 -3.74526455e-04 -1.32771587e-04  2.24390315e-04\n",
      "  -1.63505902e-03  6.79529563e-04 -4.71831328e-04 -1.49141194e-03\n",
      "  -9.58923541e-04  1.28488595e-04 -8.46896364e-05 -4.81247553e-04\n",
      "  -2.32301347e-04 -7.81629700e-04  1.47115919e-04 -3.64708867e-05\n",
      "   1.07858745e-04  4.60404670e-04 -5.35218744e-04 -4.24263242e-04\n",
      "  -6.65711472e-04  7.98085384e-05 -6.54394215e-04]]\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predictions for /private/var/folders/wy/99dkswn162g8dvl4934_v1rr0000gn/T/gradio/6d018de720eea58f30db5c238742a615b46e8f9fdca9bf5b7895088954027c6a/10000000 6110465729036786 6689576925545987563 n.mp4: [[3.8768508]\n",
      " [3.8767734]\n",
      " [3.8767056]\n",
      " [3.8767185]\n",
      " [3.8767195]]\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "def gradio_interface():\n",
    "    with gr.Blocks() as athletics_app:\n",
    "        gr.Markdown(\"# Athletics Evaluation System\")\n",
    "\n",
    "        with gr.Tab(\"Upload and Process Video\"):\n",
    "            sport_branch_input = gr.Dropdown(\n",
    "                list(SPORT_BRANCH_MODEL_MAPPING.keys()),\n",
    "                label=\"Select Sport Branch *\"\n",
    "            )\n",
    "            video_input = gr.Video(label=\"Upload 3D Video * (Ensure proper format)\")\n",
    "            process_btn = gr.Button(\"Process Video\")\n",
    "            output = gr.Textbox(label=\"Processing Result\", interactive=False)\n",
    "\n",
    "            def process_and_display(video, sport_branch):\n",
    "                if not video:\n",
    "                    return \"Error: Please upload a video file.\"\n",
    "                if not sport_branch:\n",
    "                    return \"Error: Please select a sport branch.\"\n",
    "                return process_video(video, sport_branch)\n",
    "\n",
    "            process_btn.click(\n",
    "                process_and_display,\n",
    "                inputs=[video_input, sport_branch_input],\n",
    "                outputs=output\n",
    "            )\n",
    "\n",
    "    athletics_app.launch(debug=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gradio_interface()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rl-env)",
   "language": "python",
   "name": "rl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
